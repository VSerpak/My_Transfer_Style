This is one of the Udacity Nanodegree program DEEP LEARNING FOUNDATION Lesson 4 Style Transfer. All credits are going to 
@misc{engstrom2016faststyletransfer,
    author = {Logan Engstrom},
    title = {Fast Style Transfer},
    year = {2016},
    howpublished = {\url{https://github.com/lengstrom/fast-style-transfer/}},
    note = {commit xxxxxxx}
  }
  
  SHORT LESSON DESCRIPTION
  
  Style Transfer
As an example of the kind of things you'll be building with deep learning models, here is a really fun project, fast style transfer. Style transfer allows you to take famous paintings, and recreate your own images in their styles! The network learns the underlying techniques of those paintings and figures out how to apply them on its own. This model was trained on the styles of famous paintings and is able to transfer those styles to other images and even videos!

I used it to style my cat Chihiro in the style of Hokusai's The Great Wave Off Kanagawa.

To try it out yourself, you can find the code in the fast-style-transfer GitHub repo. Either use git to clone the repository, or you can download the whole thing as a Zip archive and extract it.

The network has been trained on a few different styles (here) and saved into checkpoint files. Checkpoint files contain all the information about the trained network to apply styles to new images.

Dependencies
The easiest way to install all the packages needed to run this code is with Miniconda, a smaller version of Anaconda. Miniconda comes with Conda, a package and environment manager built specifically for data science. Install the Python 3 version of Miniconda appropriate for your operating system.

If you haven't used Conda before, please quickly run through our tutorial.

Windows
For Windows, you'll need to install TensorFlow 0.12.1, Python 3.5, Pillow 3.4.2, scipy 0.18.1, and numpy 1.11.2. After installing Miniconda, open your command prompt. In there, enter these commands line by line:

conda create -n style-transfer python=3.5
activate style-transfer
pip install tensorflow
conda install scipy pillow
The first line creates a new environment that will hold the packages needed for the style transfer code. The next line (activate style-transfer) enters the environment, you should see the environment name in the prompt at the beginning of the line. The next two install TensorFlow, Scipy, and Pillow (an image processing library).

OS X and Linux
For OS X and Linux, you'll need to install TensorFlow 0.11.0, Python 2.7.9, Pillow 3.4.2, scipy 0.18.1, and numpy 1.11.2.

In your terminal, enter this commands line by line:

conda create -n style-transfer python=2.7.9
source activate style-transfer
pip install tensorflow
conda install scipy pillow
The first line creates a new environment that will hold the packages needed for the style transfer code. The next line (source activate style-transfer) enters the environment, , you should see the environment name in the prompt at the beginning of the line. The next two install TensorFlow, Scipy, and Pillow (an image processing library).
Transferring styles
Download the Zip archive from the fast-style-transfer repository and extract it. You can download it by clicking on the bright green button on the right.
Download the Rain Princess checkpoint from here. Put it in the fast-style-transfer folder. A checkpoint file is a model that already has tuned parameters. By using this checkpoint file, we won't need to train the model and can get straight to applying it.
Copy the image you want to style into the fast-style-transfer folder.
Enter the Conda environment you created above, if you aren't still in it.
In your terminal, navigate to the fast-style-transfer folder and enter
python evaluate.py --checkpoint ./rain-princess.ckpt --in-path <path_to_input_file> --out-path ./output_image.jpg
Note: Your checkpoint file might be named rain_princess.ckpt, notice the underscore, it's not the dash from above.
You can get more checkpoint files at the bottom of this page. Try them all!

Share what you create in the forums or on the Slack channel #l-applying-dl. We'd love to see what you come up with. Also, feel free to train the network on your own images, you can find instructions in the repository (although it does take some powerful hardware).

Note: Be careful with the size of the input image. The style transfer can take quite a while to run on larger images.

The checkpoints were trained on the following paintings:

Rain Princesss, by Leonid Afremov
La Muse, by Pablo Picasso
Udnie by Francis Picabia
Scream, by Edvard Munch
The Great Wave off Kanagawa, by Hokusai
The Shipwreck of the Minotaur, by J.M.W. Turner
Supporting Materials

https://d17h27t6h515a5.cloudfront.net/topher/2017/January/587d1865_rain-princess/rain-princess.ckpt
https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa800_la-muse/la-muse.ckpt
https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa846_udnie/udnie.ckpt
https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa883_scream/scream.ckpt
https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa89d_wave/wave.ckpt
https://d17h27t6h515a5.cloudfront.net/topher/2017/January/588aa8b6_wreck/wreck.ckpt
